{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRTtgVbCrUXAF/ogeC1ubn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chimmanakhyathi/Intelligent-Resume-Praser-using-NLP/blob/main/Untitled19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fG_WlBPV0_GQ",
        "outputId": "e4ec5669-ecd0-472e-f14b-8aab350ed2b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pdfminer.six\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from pdfminer.six) (2.1.1)\n",
            "Collecting cryptography>=36.0.0\n",
            "  Downloading cryptography-39.0.0-cp36-abi3-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.8/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
            "Installing collected packages: cryptography, pdfminer.six\n",
            "Successfully installed cryptography-39.0.0 pdfminer.six-20221105\n"
          ]
        }
      ],
      "source": [
        "pip install pdfminer.six"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install docx2txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDcgxX5R2GT-",
        "outputId": "6e95fd98-1058-4e50-c206-fc2172033c0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting docx2txt\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: docx2txt\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3980 sha256=c3486988da538372c16cb3e4c4f655de660770014588b0f81d1dee34200a3f71\n",
            "  Stored in directory: /root/.cache/pip/wheels/55/f0/2c/81637d42670985178b77df6d41b9b6c6dc18c94818447414b9\n",
            "Successfully built docx2txt\n",
            "Installing collected packages: docx2txt\n",
            "Successfully installed docx2txt-0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import docx2txt\n",
        "\n",
        "\n",
        "def extract_text_from_docx(docx_path):\n",
        "    txt = docx2txt.process(docx_path)\n",
        "    if txt:\n",
        "        return txt.replace('\\t', ' ')\n",
        "    return None\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(extract_text_from_docx('/content/19A81A05P5 chimmana khyathi sri (1).docx'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cedjJK911FI",
        "outputId": "6ca4d354-c1c2-4514-cf96-2391fcc21e96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chimmana.khyathi sri\n",
            "\n",
            "Email:19a81a05p5@sves.org.in Phone no:9492154833\n",
            "\n",
            "CAREER OBJECTIVE:\n",
            "\n",
            "To work in a challenging atmosphere by exhibiting my skills with utmost sincerity and dedicated smart work for the growth of esteemed organization along with mine.\n",
            "\n",
            "ACADEMIC QUALIFICATIONS:\n",
            "\n",
            "10th Standard-S.F.S School,Tanuku Intermediate-Pragathi Junior college\n",
            "\n",
            "B.Tech(Computer Science And Engineering)-Sri Vasavi Engineering college\n",
            "\n",
            "Technical Qualifications:\n",
            "\n",
            "  Operating Systems :Unix\n",
            "\n",
            "  Languages:C,C++,Java,Python Certificates:\n",
            "\n",
            "AWS-cloud foundation AWS-machine learning NPTEL-Java Programming\n",
            "\n",
            "Coursera-HTML,javascript,CSS\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Skills:\n",
            "\n",
            "Have good Interpersonal Skills Have good leadership skills Elegant Team builder\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Personal Details:\n",
            "\n",
            "Date of Birth:25-07-2002 FatherName:Chimmana.Satyanarayana Raju Occupation:Teacher MotherName:Vaddi.Baby Rani Occupation:Govt Teacher\n",
            "\n",
            "Hobbies:Dancing Decleration:\n",
            "\n",
            "I here by declare that the above mentioned details are true to best of my knowledge.\n",
            "\n",
            "Signature: Ch.khyathi sri\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_Jig07O2U_z",
        "outputId": "d4d6c47e-600f-4d1a-b475-fec26d8ce71b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xNKEXSb2bWC",
        "outputId": "fc4389ec-9de1-43c8-fd26-f00d3d412727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VxYeg57p3B9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import docx2txt\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "\n",
        "\n",
        "def extract_text_from_docx(docx_path):\n",
        "    txt = docx2txt.process(docx_path)\n",
        "    if txt:\n",
        "        return txt.replace('\\t', ' ')\n",
        "    return None\n",
        "\n",
        "\n",
        "def extract_names(txt):\n",
        "    person_names = []\n",
        "\n",
        "    for sent in nltk.sent_tokenize(txt):\n",
        "        for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
        "            if hasattr(chunk, 'label') and chunk.label() == 'PERSON':\n",
        "                person_names.append(\n",
        "                    ' '.join(chunk_leave[0] for chunk_leave in chunk.leaves())\n",
        "                )\n",
        "\n",
        "    return person_names\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    text = extract_text_from_docx('/content/19A81A05P5 chimmana khyathi sri (1).docx')\n",
        "    names = extract_names(text)\n",
        "\n",
        "    if names:\n",
        "        print(names[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pLlE2DI2pOY",
        "outputId": "a91b7eee-cd98-454d-80a6-e56f063bd8f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "from pdfminer.high_level import extract_text\n",
        "\n",
        "EMAIL_REG = re.compile(r'[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+')\n",
        "\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    return extract_text(pdf_path)\n",
        "\n",
        "\n",
        "def extract_emails(resume_text):\n",
        "    return re.findall(EMAIL_REG, resume_text)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    text = extract_text_from_docx('/content/19A81A05P5 chimmana khyathi sri (1).docx')\n",
        "    emails = extract_emails(text)\n",
        "\n",
        "    if emails:\n",
        "        print(emails[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W00AidUe3I8T",
        "outputId": "4577415f-2426-4f37-ad79-120ec551b169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19a81a05p5@sves.org.in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import docx2txt\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "SKILLS_DB = [\n",
        "    'machine learning',\n",
        "    'data science',\n",
        "    'python',\n",
        "    'word',\n",
        "    'excel',\n",
        "    'English',\n",
        "]\n",
        "\n",
        "\n",
        "def extract_text_from_docx(docx_path):\n",
        "    txt = docx2txt.process(docx_path)\n",
        "    if txt:\n",
        "        return txt.replace('\\t', ' ')\n",
        "    return None\n",
        "\n",
        "\n",
        "def extract_skills(input_text):\n",
        "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "    word_tokens = nltk.tokenize.word_tokenize(input_text)\n",
        "\n",
        "    filtered_tokens = [w for w in word_tokens if w not in stop_words]\n",
        "\n",
        "\n",
        "    filtered_tokens = [w for w in word_tokens if w.isalpha()]\n",
        "\n",
        "\n",
        "    bigrams_trigrams = list(map(' '.join, nltk.everygrams(filtered_tokens, 2, 3)))\n",
        "\n",
        "\n",
        "    found_skills = set()\n",
        "\n",
        "\n",
        "    for token in filtered_tokens:\n",
        "        if token.lower() in SKILLS_DB:\n",
        "            found_skills.add(token)\n",
        "\n",
        "    for ngram in bigrams_trigrams:\n",
        "        if ngram.lower() in SKILLS_DB:\n",
        "            found_skills.add(ngram)\n",
        "\n",
        "    return found_skills\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    text = extract_text_from_docx('/content/19A81A05P5 chimmana khyathi sri (1).docx')\n",
        "    skills = extract_skills(text)\n",
        "\n",
        "    print(skills)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmbpFawk3lTZ",
        "outputId": "2e0432c1-5b94-4e86-e48c-029f08c4909f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Python'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job_description = docx2txt.process('/content/job_description.docx')\n",
        "resume = docx2txt.process('/content/19A81A05P5 chimmana khyathi sri (1).docx')"
      ],
      "metadata": {
        "id": "cxM8ouhf4KrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(job_description)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLj_1Ei54YW0",
        "outputId": "acb4e026-615e-4e96-d943-41a4a650d3c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job brief\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tWe are looking for a Senior Web Developer to build and maintain functional web pages and applications.\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tSenior Web Developer responsibilities include leading a team of junior developers, refining website specifications and resolving technical issues. To be successful in this role, you should have extensive experience building web pages from scratch and in-depth knowledge of at least one of the following programming languages: Javascript, Ruby or PHP.\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tUltimately, you will ensure our web pages are up and running and cover both internal and customer needs.\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tResponsibilities\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tIdentify user and system requirements for new websites and applications\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tPrioritize software development projects, set timelines and assign tasks to team members\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tCreate wireframes to decide on layout\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tWrite or review code for various applications\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tRun functionality testings and debug code\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tOversee junior web developers and evaluate their performance\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLiaise with designers to decide on UI/UX elements (like graphics and navigation buttons)\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tEnsure our software documentation is up-to-date\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tCollaborate with mobile developers to build mobile-responsive websites\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tRequirements\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tWork experience as a Senior Web Developer\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tExpertise in at least one programming language, preferably Javascript, Ruby or PHP\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tSolid knowledge of HTML/CSS\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tExperience with mockup and UI prototyping tools\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tUnderstanding of security practices\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tFamiliarity with network diagnostics tools\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tTeam management skills\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tBSc/MSc in Computer Science or relevant field\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "content = [job_description, resume]"
      ],
      "metadata": {
        "id": "jEmL3jlW4cEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer()\n",
        "count_matrix = cv.fit_transform(content)"
      ],
      "metadata": {
        "id": "LlTKUl1a4gPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "mat = cosine_similarity(count_matrix)\n",
        "print(mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2T72_-0c4j0c",
        "outputId": "7afc3ff1-0ba8-441a-ef78-29f865796a91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.         0.29823797]\n",
            " [0.29823797 1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Resume Matches by: '+  str(mat[1][0]*100) + '%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7k8CCYvc4niM",
        "outputId": "3af2ef01-974c-4565-aef4-9d552a06e7b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resume Matches by: 29.823796737526514%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.gridspec import GridSpec\n",
        "import re\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "fv4EWr6ZPcNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resumeDataSet = pd.read_csv('UpdatedResumeDataSet.csv.zip' ,encoding='utf-8')"
      ],
      "metadata": {
        "id": "yJiXKU_1PuMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cleanResume(resumeText):\n",
        "    resumeText = re.sub('httpS+s*', ' ', resumeText)  # remove URLs\n",
        "    resumeText = re.sub('RT|cc', ' ', resumeText)  # remove RT and cc\n",
        "    resumeText = re.sub('#S+', '', resumeText)  # remove hashtags\n",
        "    resumeText = re.sub('@S+', '  ', resumeText)  # remove mentions\n",
        "    resumeText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[]^_`{|}~\"\"\"), ' ', resumeText)  # remove punctuations\n",
        "    resumeText = re.sub(r'[^x00-x7f]',r' ', resumeText)\n",
        "    resumeText = re.sub('s+', ' ', resumeText)  # remove extra whitespace\n",
        "    return resumeText\n",
        "resumeDataSet['cleaned_resume'] = resumeDataSet.Resume.apply(lambda x: cleanResume(x))\n",
        "var_mod = ['Category']\n",
        "le = LabelEncoder()\n",
        "for i in var_mod:\n",
        "    resumeDataSet[i] = le.fit_transform(resumeDataSet[i])\n",
        "requiredText = resumeDataSet['cleaned_resume'].values\n",
        "requiredTarget = resumeDataSet['Category'].values\n",
        "word_vectorizer = TfidfVectorizer(\n",
        "    sublinear_tf=True,\n",
        "    stop_words='english',\n",
        "    max_features=1500)\n",
        "word_vectorizer.fit(requiredText)\n",
        "WordFeatures = word_vectorizer.transform(requiredText)"
      ],
      "metadata": {
        "id": "zcsea_PqTyFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(WordFeatures,requiredTarget,random_state=0, test_size=0.2)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "clf = OneVsRestClassifier(KNeighborsClassifier())\n",
        "clf.fit(X_train, y_train)\n",
        "prediction = clf.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-S5byHlT2Ld",
        "outputId": "c2a186f3-ee98-42d8-f259-d0b303e686af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(769, 1500)\n",
            "(193, 1500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy of KNeighbors Classifier on training set: {:.2f}'.format(clf.score(X_train, y_train)))\n",
        "print('Accuracy of KNeighbors Classifier on test set: {:.2f}'.format(clf.score(X_test, y_test)))\n",
        "print(\"n Classification report for classifier %s:n%sn\" % (clf, metrics.classification_report(y_test, prediction)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Edc_vObtUQST",
        "outputId": "db970f89-f778-4ef2-ce52-4c32a1244445"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of KNeighbors Classifier on training set: 0.99\n",
            "Accuracy of KNeighbors Classifier on test set: 0.99\n",
            "n Classification report for classifier OneVsRestClassifier(estimator=KNeighborsClassifier()):n              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         3\n",
            "           1       1.00      1.00      1.00         3\n",
            "           2       1.00      0.80      0.89         5\n",
            "           3       1.00      1.00      1.00         9\n",
            "           4       1.00      1.00      1.00         6\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       1.00      1.00      1.00         9\n",
            "           7       1.00      1.00      1.00         7\n",
            "           8       1.00      0.91      0.95        11\n",
            "           9       1.00      1.00      1.00         9\n",
            "          10       1.00      1.00      1.00         8\n",
            "          11       0.90      1.00      0.95         9\n",
            "          12       1.00      1.00      1.00         5\n",
            "          13       1.00      1.00      1.00         9\n",
            "          14       1.00      1.00      1.00         7\n",
            "          15       1.00      1.00      1.00        19\n",
            "          16       1.00      1.00      1.00         3\n",
            "          17       1.00      1.00      1.00         4\n",
            "          18       1.00      1.00      1.00         5\n",
            "          19       1.00      1.00      1.00         6\n",
            "          20       1.00      1.00      1.00        11\n",
            "          21       1.00      1.00      1.00         4\n",
            "          22       1.00      1.00      1.00        13\n",
            "          23       1.00      1.00      1.00        15\n",
            "          24       0.89      1.00      0.94         8\n",
            "\n",
            "    accuracy                           0.99       193\n",
            "   macro avg       0.99      0.99      0.99       193\n",
            "weighted avg       0.99      0.99      0.99       193\n",
            "n\n"
          ]
        }
      ]
    }
  ]
}